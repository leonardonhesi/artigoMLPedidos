{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib            as jb\n",
    "import seaborn           as sns\n",
    "\n",
    "from sklearn.metrics                  import roc_auc_score\n",
    "from sklearn.metrics                  import average_precision_score\n",
    "from sklearn.model_selection          import GridSearchCV\n",
    "from sklearn.model_selection          import RandomizedSearchCV\n",
    "from sklearn.model_selection          import StratifiedKFold\n",
    "\n",
    "from lightgbm                         import LGBMClassifier\n",
    "from sklearn.ensemble                 import RandomForestClassifier\n",
    "from sklearn.naive_bayes              import GaussianNB\n",
    "from sklearn.neighbors                import KNeighborsClassifier\n",
    "from sklearn.svm                      import SVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dataSet com as mehores features\n",
    "\n",
    "X_train             = jb.load(\"../dados/treino/X_trainFinal.pkl.z\")\n",
    "y_train             = jb.load(\"../dados/treino/y_trainFinal.pkl.z\")\n",
    "X_test              = jb.load(\"../dados/teste/X_testeFinal.pkl.z\")\n",
    "y_test              = jb.load(\"../dados/teste/y_testeFinal.pkl.z\")\n",
    "\n",
    "# X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (Parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alimentar uma variavel com os possiveis valores atribuidos a cada parametro\n",
    "grid_param = {'n_estimators':     [500, 800, 1500, 2000, 5000],\n",
    "             'max_features':      ['auto','sqrt','log2'],\n",
    "             'max_depth':         [10,24,32,64,128],\n",
    "             'min_samples_split': [2,50,100,200,500],\n",
    "             'min_samples_leaf':  [5,10,15,20,50]}\n",
    "# Setup inicial do metodo de busca informando o modelo que sera utilizado\n",
    "res_prm = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=1),\n",
    "                             param_distributions=grid_param,\n",
    "                             n_iter=500,\n",
    "                             cv=5,\n",
    "                            verbose=2,\n",
    "                            random_state=42,n_jobs=6)\n",
    "# Iniciar o trabalho de treinamento(fit) do modelo com cada combinação de parametro com objetivo\n",
    "# de encontrar a melhor combinação.\n",
    "# res_prm.fit(X_train, y_train) #descomentar esta linha para procurar os parametros\n",
    "print(res_prm.best_params_)\n",
    "'''\n",
    " {'n_estimators': 1500,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 5,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 64}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Random Forest (Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.9410726637585005\n",
      "roc auc Score: 0.8721428759020675\n"
     ]
    }
   ],
   "source": [
    "# Utilizar o melhor parametro\n",
    "mdl_rf = RandomForestClassifier(n_estimators=1500,\n",
    "                                random_state=1,\n",
    "                                max_depth=64,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=5, \n",
    "                                class_weight=\"balanced\",\n",
    "                                n_jobs=6,\n",
    "                                min_samples_split=2)\n",
    "mdl_rf.fit(X_train, y_train)\n",
    "p_rf = mdl_rf.predict_proba(X_test)[:, 1]\n",
    "print('Average:'      , average_precision_score(y_test, p_rf))\n",
    "print('roc auc Score:', roc_auc_score(y_test, p_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.9643243455221865\n",
      "roc: 0.9251570017416255\n"
     ]
    }
   ],
   "source": [
    "params = [0.01, 5, 2, 1, 1, 2000]\n",
    "lr = params[0]\n",
    "max_depth = params[1]\n",
    "min_child_samples = params[2]\n",
    "subsample = params[3]\n",
    "colsample_bytree = params[4]\n",
    "n_estimators = params[5]\n",
    "mdl_lgbm = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth,\n",
    "                          max_depth=max_depth,min_child_samples=min_child_samples,\n",
    "                          subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                          bagging_freq=1,n_estimators=n_estimators,\n",
    "                          random_state=20,class_weight=\"balanced\",n_jobs=6)\n",
    "mdl_lgbm.fit(X_train, y_train)\n",
    "p_lgbm = mdl_lgbm.predict_proba(X_test)[:, 1]\n",
    "print('Average:'      ,average_precision_score(y_test, p_lgbm) )\n",
    "print('roc:'          ,roc_auc_score(y_test, p_lgbm) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (Gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.7216729326800552\n",
      "roc auc Score: 0.5832553990934625\n",
      "NB Score: 0.7098773935803829\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n",
    "p_nb = gnb.predict_proba(X_test)[:, 1]\n",
    "print('Average:'      , average_precision_score(y_test, p_nb))\n",
    "print('roc auc Score:', roc_auc_score(y_test, p_nb))\n",
    "print('NB Score:'     , gnb.score(X_test, y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.8266299483788582\n",
      "roc auc Score: 0.7179321514311299\n",
      "KNN Score: 0.7346741975478716\n"
     ]
    }
   ],
   "source": [
    "knn   = KNeighborsClassifier()\n",
    "#Buscar melhores parametros\n",
    "# k_list         = list(range(1,31))\n",
    "# p              = list(range(1,10))\n",
    "# weights        = ['uniform', 'distance']\n",
    "# algorithm      = ['auto', 'ball_tree', 'kd_tree']\n",
    "# leaf_size      = list(range(10,40))\n",
    "# parametros     = dict(n_neighbors=k_list,\n",
    "#                       p=p,\n",
    "#                       weights=weights,\n",
    "#                       algorithm=algorithm,\n",
    "#                       leaf_size=leaf_size)\n",
    "# grid = GridSearchCV(knn, parametros, cv=5, scoring='accuracy', n_jobs=6)\n",
    "# grid.fit(X_train, y_train)\n",
    "# grid = grid.best_params_\n",
    "grid = {'algorithm':   'auto',\n",
    "        'leaf_size':   28,\n",
    "        'n_neighbors': 22,\n",
    "        'p': 1,\n",
    "        'weights': 'distance'}\n",
    "\n",
    "# Utiliza os melhores parametros\n",
    "knn   = KNeighborsClassifier(n_neighbors=grid['n_neighbors'], \n",
    "                             p=grid['p'],\n",
    "                             weights=grid['weights'],\n",
    "                             algorithm=grid['algorithm'],\n",
    "                             leaf_size=grid['leaf_size'])\n",
    "knn.fit( X_train, y_train)\n",
    "p_knn = knn.predict_proba(X_test)[:, 1]\n",
    "print('Average:'      , average_precision_score(y_test, p_knn))\n",
    "print('roc auc Score:', roc_auc_score(y_test, p_knn))\n",
    "print('KNN Score:'    , knn.score(X_test, y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.6974789915966386\n",
      "Score Mean: 0.5\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='poly', gamma=1)\n",
    "svclassifier.fit(X_train, y_train)\n",
    "p_svn = svclassifier.predict(X_test)\n",
    "p_svnScore = svclassifier.score(X_test, y_test)\n",
    "print('Average:'      , average_precision_score(y_test, p_svn ))\n",
    "print('Score Mean:', roc_auc_score(y_test, p_svn ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         RF      LGBM        NB       SVN      KNN     GERAL\n",
      "0  0.941073  0.964324  0.721673  0.697479  0.82663  0.944403\n",
      "         RF      LGBM        NB  SVN       KNN     GERAL\n",
      "0  0.872143  0.925157  0.583255  0.5  0.717932  0.882449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (p_rf + p_lgbm + p_nb + p_knn + p_svn ) / 5\n",
    "average = pd.DataFrame({\"RF\":     [average_precision_score(y_test, p_rf)],\n",
    "              \"LGBM\":   [average_precision_score(y_test, p_lgbm)],\n",
    "              \"NB\":     [average_precision_score(y_test, p_nb)],\n",
    "              \"SVN\":    [average_precision_score(y_test, p_svn)],\n",
    "              \"KNN\":    [average_precision_score(y_test, p_knn)],\n",
    "              \"GERAL\":  [average_precision_score(y_test, p)]})\n",
    "roc = pd.DataFrame({\"RF\":     [roc_auc_score(y_test, p_rf)],\n",
    "              \"LGBM\":   [roc_auc_score(y_test, p_lgbm)],\n",
    "              \"NB\":     [roc_auc_score(y_test, p_nb)],\n",
    "              \"SVN\":    [roc_auc_score(y_test, p_svn)],\n",
    "              \"KNN\":    [roc_auc_score(y_test, p_knn)],\n",
    "              \"GERAL\":  [roc_auc_score(y_test, p)]})\n",
    "print(average), print(roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../modelos_treinados/SVM/SVM.pkl.z']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb.dump(mdl_lgbm     , \"../modelos_treinados/LGBM/lgbm.pkl.z\")\n",
    "jb.dump(mdl_rf       , \"../modelos_treinados/randomForest/random_forest.pkl.z\")\n",
    "jb.dump(gnb          , \"../modelos_treinados/naiveBayes/naiveBayes.pkl.z\")\n",
    "jb.dump(knn          , \"../modelos_treinados/KNN/knn.pkl.z\")\n",
    "jb.dump(svclassifier , \"../modelos_treinados/SVM/SVM.pkl.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
